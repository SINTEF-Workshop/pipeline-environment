[2022-10-05T08:55:22.802+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: dump_to_s3.create_dump_file manual__2022-10-05T08:55:20.144869+00:00 [queued]>
[2022-10-05T08:55:22.808+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: dump_to_s3.create_dump_file manual__2022-10-05T08:55:20.144869+00:00 [queued]>
[2022-10-05T08:55:22.808+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-10-05T08:55:22.808+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-10-05T08:55:22.808+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-10-05T08:55:22.894+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): create_dump_file> on 2022-10-05 08:55:20.144869+00:00
[2022-10-05T08:55:22.896+0000] {standard_task_runner.py:54} INFO - Started process 7982 to run task
[2022-10-05T08:55:22.900+0000] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'dump_to_s3', 'create_dump_file', 'manual__2022-10-05T08:55:20.144869+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp2vtuzwit']
[2022-10-05T08:55:22.901+0000] {standard_task_runner.py:83} INFO - Job 29: Subtask create_dump_file
[2022-10-05T08:55:22.902+0000] {dagbag.py:525} INFO - Filling up the DagBag from /workspaces/pipeline-environment/test_airflow/dags/pipeline.py
[2022-10-05T08:55:22.985+0000] {logging_mixin.py:117} WARNING - /usr/local/lib/python3.10/site-packages/airflow/models/dag.py:3393 RemovedInAirflow3Warning: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead.
[2022-10-05T08:55:22.987+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): create_dump_file>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.987+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, create_dump_file already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.987+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): create_dump_file>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.987+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, create_dump_file already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.988+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): create_dump_file>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.988+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, create_dump_file already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.988+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): create_dump_file>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.988+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, create_dump_file already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.988+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): create_dump_file>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.988+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, create_dump_file already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.988+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): create_dump_file>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.988+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, create_dump_file already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.989+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, dump_to_s3 already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.989+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): dump_to_s3>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.989+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, dump_to_s3 already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.989+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): dump_to_s3>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.989+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, dump_to_s3 already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.989+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): dump_to_s3>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.989+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, dump_to_s3 already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.990+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): dump_to_s3>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.990+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, dump_to_s3 already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.990+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): dump_to_s3>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.990+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): collect_messages>, dump_to_s3 already registered for DAG: dump_to_s3
[2022-10-05T08:55:22.990+0000] {taskmixin.py:205} WARNING - Dependency <Task(_PythonDecoratedOperator): dump_to_s3>, collect_messages already registered for DAG: dump_to_s3
[2022-10-05T08:55:23.054+0000] {task_command.py:384} INFO - Running <TaskInstance: dump_to_s3.create_dump_file manual__2022-10-05T08:55:20.144869+00:00 [running]> on host b44ee3804a1a
[2022-10-05T08:55:23.151+0000] {taskinstance.py:1590} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dump_to_s3
AIRFLOW_CTX_TASK_ID=create_dump_file
AIRFLOW_CTX_EXECUTION_DATE=2022-10-05T08:55:20.144869+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-10-05T08:55:20.144869+00:00
[2022-10-05T08:55:23.152+0000] {logging_mixin.py:117} INFO - end_time
[2022-10-05T08:55:23.152+0000] {logging_mixin.py:117} INFO - 2022-10-05 06:55:23.152309+00:00
[2022-10-05T08:55:23.152+0000] {logging_mixin.py:117} INFO - start_time
[2022-10-05T08:55:23.152+0000] {logging_mixin.py:117} INFO - 2022-10-04 08:55:23.152327+00:00
[2022-10-05T08:55:23.152+0000] {python.py:177} INFO - Done. Returned value was: {'now': datetime.datetime(2022, 10, 5, 6, 55, 23, 152309, tzinfo=<UTC>), 'start_time': datetime.datetime(2022, 10, 4, 8, 55, 23, 152327, tzinfo=<UTC>)}
[2022-10-05T08:55:23.154+0000] {xcom.py:599} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config.
[2022-10-05T08:55:23.154+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2378, in xcom_push
    XCom.set(
  File "/usr/local/lib/python3.10/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/airflow/models/xcom.py", line 206, in set
    value = cls.serialize_value(
  File "/usr/local/lib/python3.10/site-packages/airflow/models/xcom.py", line 597, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/local/lib/python3.10/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/local/lib/python3.10/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.10/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.10/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type datetime is not JSON serializable
[2022-10-05T08:55:23.167+0000] {taskinstance.py:1401} INFO - Marking task as FAILED. dag_id=dump_to_s3, task_id=create_dump_file, execution_date=20221005T085520, start_date=20221005T085522, end_date=20221005T085523
[2022-10-05T08:55:23.203+0000] {standard_task_runner.py:102} ERROR - Failed to execute job 29 for task create_dump_file (Object of type datetime is not JSON serializable; 7982)
[2022-10-05T08:55:23.232+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-10-05T08:55:23.301+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
